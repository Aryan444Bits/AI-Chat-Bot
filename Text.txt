Vector DataBase 

-> this database is used to save the data in the form of the vectors(array of floating numbers)

-> suppose there is an word ring = [-0.2254585, -0.0885454555, 0.255544] jiska ye number h jo ki represent krta hai ring word ko.

-> ye to number hia inki ek range defined hai ki ye -1 > n & n < 1 

-> ek word ko define krne ke liye vector me hmmre pass kai combination hote hai like 1024, 3072, 768.

-> Vectors is also known as embedding and for the creating a vector of any string we use models we give the string to the AI-Models and it converted into vector form for this we use model :- gemini-embiding-001. its length is not fixed it depends on the which combination we used

example : ring == gemini-embiding-001 =>[-0.1224, 0.2244, -0.0.2545] (length of array is 768)


-> we take an example of a vector which having 3 co-ordinates that array of folating numbers are the nothing the are co-ordinates where with the help of that coordinates all the words are plotted in the graphs.



-> now here we understand how ai will remember our past and too past data in long term memory like vector database : -


1> here we have a message for ai : i have a new phone and ai send the message congratulations

2> now first it store in the memory but after some time it converted it into vector form and plot that points in the graph

3> suppose after 10 months user send the message : do you remember i have new phone then now the game begins :

i have a new phone ---> [-0.2254585, -0.0885454555, 0.255544] suppose these are the coordinate of this message

do you remember i have new mobile -----> [-0.4454585, -0.0885454556, 0.255548] and this is the co-ordinate of this message 

now mobile and phone idhr kaafi relatable words hai to inke jo vectors hai wo kaffi hadd tk similar honge and now jab hm inhe plot krenge to dono kaafi pass pass plot hone isilye jab bhi use koi purani chije puchta h  to wo sab se phle vector me connvert hoti and then wo plotting are me jaake similar point dhund ke unke vetors ko return krti hai aur hmra model usse vector wapas string me convert krta hai aur hmme data mil jata h


now see both context are about phone so dono ke cordinate me koi major changes nhi hoga dono kaafi pass me placed honge...

yahi puri same kahani tm embeded projection me jaake dekh skte ho jo words ek dusre se kisi bhi trike thoda bhut link krte honge un sabhi ko kaafi pass pass placed kiya gaya hoga 

aur rhi baat dimension ki to vector me hmre pass kaai combinations hote h to ye koi jaruri nhi h ki 3D me hi ho agar hm 768 combination bhi us ekre to hmare leiye ye bhut hi muskil hoga usse pure data ka graph imagin krna


Flow of going message to the ai model :

-> when we pass the message to the ai it doesent goes directly it passes trhough the multiple levels like tokennization, embedding...

-> now here is the flow when we give any text to the ai model it first goest through the tokennization means isme jitne bhi unuseable words hai unko remove kr diya jata h aur sirf unhi words ko sav krte h jina hmme kam hota h lets take one example :

the car is running on the highway at the speed of 120 km/h
                           | 
                           |
                           |   tokennization
                           |
                           |
             car run highway speed 120 km/h
                           |
                           |
                           | emmbeding
                           |
                           |
                   gemini-2.0-flash
                           |
                           |
                           |
                           |
                           |
                         Output


this how the flow goes to the ai model before we get out Outputfrom the AI



AI-Generated Structured Response : 

ðŸ§  Vector Database â€“ Refined Explanation

1> Definition :

-> A vector database stores data in the form of vectors (arrays of floating-point numbers).

Example:

"ring" â†’ [-0.2254, -0.0885, 0.2555]

-> Ye numbers AI model ke hisaab se word â€œringâ€ ka meaning represent karte hain.


2> Range of Values :

-> Vector embeddings me values mostly -1 se +1 ke beech hoti hain.


3> Dimensionality :

-> Har embedding ka ek dimension size hota hai, jaise: 128, 512, 768, 1024, 3072â€¦

-> Matlab ek hi word ko represent karne ke liye different-size ke vectors banaye ja sakte hain depending on the model.

Example:

gemini-embedding-001 â†’ 768 dimensions.


4> Embeddings :

-> Vectors ko embeddings bhi kehte hain.

-> Embeddings banane ke liye AI models use hote hain jo input string ko vector me convert kar dete hain.


5> Similarity Search :

-> Sabse badi power vector DB ki ye hai ki ye semantic similarity samajhta hai, na ki sirf exact words.

Example:

â€œphoneâ€ aur â€œmobileâ€ â†’ embeddings close hote hain.

Graph par plot karo to dono vectors pass-pass points banayenge.


6> AI Memory Example :

User: â€œI bought a new phoneâ€ â†’ convert into vector â†’ store in DB.

10 months later: â€œDo you remember I got a new mobile?â€

AI converts this to vector â†’ finds closest vector in DB (old â€œphoneâ€ memory).

Because â€œphoneâ€ â‰ˆ â€œmobileâ€, vectors close hote hain â†’ AI recalls old context.


7> Higher Dimensions :

-> Hum 2D ya 3D graph easily imagine kar sakte hain, lekin embeddings usually hundreds or thousands of dimensions ke hote hain.

-> Matlab human mind ke liye direct visualize karna mushkil hai, but mathematically ye vectors ek â€œsemantic spaceâ€ banate hain jaha similar meanings close hote hain.


ðŸ”¥ Real-World Use Cases of Vector Databases

-> Chatbots & AI memory (long-term memory jaisa tumne bola).

-> Search Engines â†’ agar tum â€œbest budget phoneâ€ search karo, vector DB tumhe â€œcheap smartphonesâ€ bhi dikhayega kyunki semantic similarity hai.

-> Recommendation Systems â†’ Netflix tumhe similar movies suggest karta hai.

-> Fraud Detection â†’ unusual patterns vectors ke through pakde jaate hain.


-------------------------------------------------------------------------


-> in this Project we make like this last ke 10 - 20 message hi database me rhenge and baaki ke saree meessage hamare vectore database me as a refference save ho jaate h. aur vector data base data kaise store hota hai  wo hmm pata hai bas fark itna hi h ki pura string nhi save hota h string ko phle tokennization kiya jatta h phir usse vector me convert krke database me store krte h phir jab sse related koi data milega to uske vector hmme pichle kisi vectorse hlka hlka similar milte h.


-> to kind of dekha jaye to ai pure trh se yaad nhi rkhta h bas usse thoda bhit context pata hota h ki kya ho raha h like dhundla dhundla.


-> iss project me ai ko hm last ke kuch hi message denge kyuki aga rhmme puri chat ai ko dedi to hmre pass kaai sare multiple input and outputs rhenge aur har ek output input ka alag alag token hota hai aur har after 1M token ke baad hmme different different charges pay krne hote h.


-> and wo apni long term memory ka usse tabhi krega jab user usser usse koi aisa question puche aur wo uske long term memory se related ho



RAG (Retrival Agumented Generation) :

ðŸ”¹ What actually happens in RAG:

1> You ask a question â†’ e.g., â€œCan you create a server with the framework we learned?â€

-> Your query is converted into a vector embedding using an embedding model.

2> Vector search in database â†’

-> That embedding is used to find the most semantically similar documents/responses from a knowledge base (stored as vectors in a vector DB).

Example: It finds past knowledge about â€œExpressâ€, â€œbackend frameworkâ€, â€œserver creationâ€.

3> Augmentation step â†’

-> Those retrieved documents are passed back into the AI model along with your query.

-> So instead of relying only on its memory, the model now has relevant external knowledge.

4> Generation step â†’

The LLM uses your query + retrieved knowledge to generate a better, context-aware answer.